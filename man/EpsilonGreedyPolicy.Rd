% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/policy_fma_epsilon_greedy.R
\name{EpsilonGreedyPolicy}
\alias{EpsilonGreedyPolicy}
\title{R6 Class representing the Finitely Many Arm Epsilon Greedy policy}
\description{
An \code{\link{EpsilonGreedyPolicy}} object implements the
  behaviour of an agent with a Epsilon Greedy Policy. It is instantiated the
  exploration parameter epsilon. The method \code{\link{run}} processes a
  reward matrix corresponding to a stochastic with finitely many arms bandit.
}
\details{
The Epsilon Greedy Algorithm is used in stochastic bandits with
  finitely many arms problems.

  When processing a reward matrix, at each iteration the agent flip a coin
  with success probability epsilon. If it succeeds he chooses at random an
  arm to pull. If not he chooses the arm with the highest observed reward
  expectation. This expectation if updated after observing the result of the
  draw.

  This class uses a \code{\link{Recorder}} object to export results.
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{name}}{Short string describing the instance.}

\item{\code{record}}{R6 object of class Recorder used to export simulation
results.}

\item{\code{epsilon}}{Exploration parameter}

\item{\code{mu_hat}}{Numeric vector containing reward expectation of each arm.}

\item{\code{N}}{Numeric vector containing number of times each arm was pulled.}

\item{\code{K}}{Integer containing the number of arms.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{EpsilonGreedyPolicy$new()}}
\item \href{#method-reset}{\code{EpsilonGreedyPolicy$reset()}}
\item \href{#method-get_action}{\code{EpsilonGreedyPolicy$get_action()}}
\item \href{#method-update_with_reward}{\code{EpsilonGreedyPolicy$update_with_reward()}}
\item \href{#method-run}{\code{EpsilonGreedyPolicy$run()}}
\item \href{#method-clone}{\code{EpsilonGreedyPolicy$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Create a new EpsilonGreedyPolicy object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{EpsilonGreedyPolicy$new(epsilon = 0.25)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{epsilon}}{Exploration parameter.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A new `EpsilonGreedyPolicy` object.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-reset"></a>}}
\if{latex}{\out{\hypertarget{method-reset}{}}}
\subsection{Method \code{reset()}}{
Set or reset object attributes before starting a simulation.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{EpsilonGreedyPolicy$reset(K)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{K}}{Number of arms.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-get_action"></a>}}
\if{latex}{\out{\hypertarget{method-get_action}{}}}
\subsection{Method \code{get_action()}}{
Chooses which arm to pull by flipping a coin and either
  explore or exploit the current best arm.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{EpsilonGreedyPolicy$get_action()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
The index of the chosen arm.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-update_with_reward"></a>}}
\if{latex}{\out{\hypertarget{method-update_with_reward}{}}}
\subsection{Method \code{update_with_reward()}}{
Updates mu_hat and N given reward r of arm a.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{EpsilonGreedyPolicy$update_with_reward(r, a)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{r}}{Reward.}

\item{\code{a}}{Arm.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-run"></a>}}
\if{latex}{\out{\hypertarget{method-run}{}}}
\subsection{Method \code{run()}}{
Process a bandit problem represented by the reward matrix.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{EpsilonGreedyPolicy$run(rewards, verbose = TRUE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{rewards}}{Reward matrix. Time on rows, arms on columns.}

\item{\code{verbose}}{Logical. if FALSE, only the coin flip value, the action
and reward history will be returned. Default is TRUE.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A tibble describing at each iteration, the reward expectation of
  each arm, the coin flip value, the action taken and the reward
  received. If verbose is FALSE, only the coin flip, the action and the
  reward.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{EpsilonGreedyPolicy$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
